 \documentclass{article}
\usepackage[utf8]{inputenc}

\title{Fall 2022 CS4641/CS7641 Homework 1}
\author{Dr. Mahdi Roozbahani}
\date{Deadline: Friday, September 23rd, 11:59 pm AOE}
\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{bbold}
\usepackage{diagbox}
\usepackage{multirow}
\usepackage{listings}


\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Sharelatex Example},
    bookmarks=true,
    pdfpagemode=FullScreen,
}

\begin{document}
\maketitle
\begin{itemize}
    \item No unapproved extension of the deadline is allowed. Late submission will lead to 0 credit.
    \item Discussion is encouraged on Ed as part of the Q/A. However, all assignments should be done individually.
    \item \color{red}Plagiarism is a \textbf{serious offense}. You are responsible for completing your own work. You are not allowed to copy and paste, or paraphrase, or submit materials created or published by others, as if you created the materials. All materials submitted must be your own.\color{black}
    \item \color{red}All incidents of suspected dishonesty, plagiarism, or violations of the Georgia Tech Honor Code will be subject to the institute’s Academic Integrity procedures. If we observe any (even small) similarities/plagiarisms detected by Gradescope or our TAs, \textbf{WE WILL DIRECTLY REPORT ALL CASES TO OSI}, which may, unfortunately, lead to a very harsh outcome. \textbf{Consequences can be severe, e.g., academic probation or dismissal, grade penalties, a 0 grade for assignments concerned, and prohibition from withdrawing from the class}.
\end{itemize}

\section*{Instructions}
\begin{itemize}
    \item This assignment has no programming, only written questions.
    \item We will be using Gradescope for submission and grading of assignments. 
    \item Unless a question explicitly states that no work is required to be shown, you must provide an explanation, justification, or calculation for your answer.
    \item Your write-up must be submitted in PDF form, you may use either Latex,  markdown, or any word processing software. \color{red}We will \textbf{NOT} accept handwritten work. \color{black}Make sure that your work is formatted correctly, for example submit $\sum_{i=0} x_i$ instead of \text{sum\_\{i=0\} x\_i}. 
    \item \textbf{A useful video tutorial on LaTeX has been created by our TA team} and can be found \href{https://www.dropbox.com/s/wywx114wtfoweru/Latex\%20Tutorial.mp4?dl=0}{here} and an Overleaf document with the commands can be found \href{https://www.overleaf.com/read/tmjnjqygqkqd}{here}.
    \item Please answer each question on a new page. It makes it more organized to map your answers on GradeScope. When submitting your assignment, you must correctly map pages of your PDF to each question/subquestion to reflect where they appear. Make sure to map the whole solution for each question/subquestion and NOT just the first page. \textbf{Improperly mapped questions may not be graded correctly or may receive point deductions. }
    \item All assignments should be done individually, each student must write up and submit their own answers.
    \item \color{red}\textbf{Graduate Students}\color{black}: You are required to complete any sections marked as Bonus for Undergrads
\end{itemize}
\newpage

\section*{Point Distribution}
\subsection*{Q1: Linear Algebra [43pts]}
\begin{itemize}
    \item 1.1 Determinant and Inverse of a Matrix [15pts]
    \item 1.2 Characteristic Equation [8pts]
    \item 1.3 Eigenvalues and Eigenvectors [20pts]
\end{itemize}
\subsection*{Q2: Covariance, Correlation, and Independence [9pts]}
\begin{itemize}
    \item 2.1 Covariance [5pts]
    \item 2.2 Correlation [4pts]
\end{itemize}
\subsection*{Q3: Optimization [19pts: 15pts + 4pts Bonus for All]}
\subsection*{Q4: Maximum Likelihood [25pts: 10pts + 15pts Bonus for Undergrads]}
\begin{itemize}
    \item 4.1 Discrete Example [10pts]
    \item 4.2 Weibull Distribution [15pts Bonus for Undergrads]
\end{itemize}
\subsection*{Q5: Information Theory [35pts]}
\begin{itemize}
    \item 5.1 Marginal Distribution [6pts]
    \item 5.2 Mutual Information and Entropy [19pts]
    \item 5.3 Entropy Proofs [10pts]
\end{itemize}
\subsection*{Q6: Bonus for All [15pts]}
\newpage

\section{Linear Algebra [15pts + 8pts + 20pts]}
\subsection{Determinant and Inverse of Matrix [15pts]}
Given a matrix $M$:
$$M = \begin{bmatrix} 
    4 & 2 & 1 \\ 
    -3 & r & 2 \\
    0 & 7 & 1
\end{bmatrix}$$
\begin{enumerate}[label=(\alph*)]
    \item Calculate the determinant of $M$ in terms of $r$. (Calculation process is required) [4pts]
    
    \item For what value(s) of $r$ does $M^{-1}$ not exist? Why? What does it mean in terms of rank and singularity for these values of $r$? [3pts]
    
    \item Will all values of $r$ found in part b allow for a column (row) to be expressed as a linear combination of the other columns (rows) respectively? If yes, provide the linear combination of $C_3$ for column or the linear combination of $R_2$ for row; if no, explain why. [3pts]
    
    \item Write down $M^{-1}$ for $r = 0$. (Calculation process is \textbf{NOT} required.) [2pts]
    
    \item Find the determinant of $M^{-1}$ for $r = 0$. What is the relationship between the determinant of $M$ and the determinant of $M^{-1}$? [3pts]
\end{enumerate}


\newpage
\subsection{Characteristic Equation [8pts]}
Consider the eigenvalue problem: 
$$Ax =\lambda x, x \neq 0$$
where $x$ is a non-zero eigenvector and $\lambda$ is eigenvalue of $A$. Prove that the determinant $|A-\lambda I|= 0$.\\ \\
\textbf{Note}: There are many ways to solve this problem. You are allowed to use linear algebra properties as part of your solution. \\
\newline


\newpage
\subsection{Eigenvalues and Eigenvectors [5+5+10pts]}
\subsubsection{Eigenvalues [5pts]}
Given a matrix A:
$$\textbf{\textit{A}}=\begin{bmatrix}
    a & b \\
    b & c
\end{bmatrix}$$
\begin{enumerate}[label=(\alph*)]
    \item Find an expression for the eigenvalues ($\lambda$) of $\textbf{\textit{A}}$ and solve for $\lambda$ in the terms given. [4pts]
    
    \item Find a simple expression for the eigenvalues if $c= a$. [1pt]
\end{enumerate}


\newpage
\subsubsection{Trace and Eigenvectors [5pts]}
A symmetric matrix $\textbf{\textit{A}}\in \mathbb{R}^{N\times N}$ can be decomposed as
$$\boldsymbol{A}=\boldsymbol{V} \boldsymbol{\Lambda } \boldsymbol{V}^T=\sum_{n=1}^N \lambda_n \boldsymbol{v}_n \boldsymbol{v}_n^T$$
Where $\boldsymbol{V}$ is a matrix whose columns are the eigenvectors of $\boldsymbol{A}$, $\boldsymbol{v}_n$ are the columns of $\boldsymbol{V}$ and $\boldsymbol{\Lambda}$ is a diagonal matrix whose elements are the eigenvalues of $\boldsymbol{A}$. The eigenvectors are orthonormal to each other, i.e., $\boldsymbol{v}_i^T\boldsymbol{v}_j=\left\{
\begin{matrix}
    1, i=j \\
    0, i\neq j
\end{matrix}\right.$.
\begin{enumerate}[label=(\alph*)]
    \item Show that $\text{trace}(\boldsymbol{A})=\sum_{n=1}^N \lambda_n$ [3pts] \\
    \textbf{NOTE:} $\boldsymbol{v}_i^T\boldsymbol{v}_j\neq \boldsymbol{v}_i\boldsymbol{v}_j^T$
    
    \item What is the result of the multiplication $\boldsymbol{V}^T \boldsymbol{V}$? Show your work or present an argument. [2pts]\\
\end{enumerate}


\newpage
\subsubsection{Eigenvalue and Eigenvector Calculations [10pts]}
Given a matrix
$$\boldsymbol{A} = \begin{bmatrix} 
    x & 5  \\ 
    5 & x \\
\end{bmatrix}$$
\begin{enumerate}[label=(\alph*)]
    \item Calculate the eigenvalues of $\boldsymbol{A}$ as a function of $x$. (Calculation process required). [3pts]
    
    \item Find the normalized eigenvectors of matrix $\boldsymbol{A}$ (Calculation process required). [7pts]
\end{enumerate}


\newpage
\section{Expectation, Co-variance and Independence [5pts + 4pts]}
\subsection{Covariance [5pts]}
Suppose $X, Y$ and $Z$ are three different random variables.
Let $X$ obey a Bernoulli Distribution. The probability distribution function is
    $$p(x)=\left\{
    \begin{array}{ c l}	
        0.6 & x = c\\
        0.4 & x = -c
    \end{array}\right.$$
where $c$ is a nonzero constant. Let $Y$ obey the Standard Normal (Gaussian) Distribution, which can be written as $Y \sim N(0,1)$. $X$ and $Y$ are independent. Meanwhile, let $Z = XY$. \\
\\
\noindent Calculate the covariance of Y and Z ($Cov(Y, Z)$). Do values of c affect the covariance between Y and Z? [5pts]


\newpage
\subsection{Correlation Coefficient [4pts]}
Let X and Y be independent random variables with $var(X) = 5$ and $var(Y ) = 15$. We do
not know $E[X]$ or $E[Y]$. Let $Z = 3X + 2Y$ . What is the correlation coefficient $\rho(X,Z)=\frac{cov(X,Z)}{\sqrt{var(X)var(Z)}}$? If applicable, please round your answer to 3 decimal places. [4pts]


\newpage
\section{Optimization [15pts + 4pts Bonus for All]}
Optimization problems are related to minimizing a function (usually termed loss, cost or error function) or maximizing a function (such as the likelihood) with respect to some variable x. The Karush-Kuhn-Tucker(KKT) conditions are first-order conditions for a solution in nonlinear programming to be optimal, provided that some regularity conditions are satisfied. In this question, you will be solving the following optimization problem:
\begin{align*}
    \max_{x,y} \qquad & f(x,y) = -4y + xy \\
    \text{s.t.} \qquad & g_{1}(x,y) = 2x^{2}+y^{2}\leq 12 \\
    & g_{2}(x,y) = x \leq 1
\end{align*}

\begin{enumerate}[label=(\alph*)]
    \item Write the Lagrange function for the maximization problem. Now change the maximum function to a minimum function (i.e. $\underset{x,y}{min} \;\; f(x,y) = -4y + xy$) and provide the Lagrange function for the minimization problem with the same constraints $g_1$ and $g_2$.  [2pts]
        \par\textbf{Note:} The minimization problem is only for part (a).
        
    \item List the names of all of the KKT conditions and its corresponding mathematical equations or inequalities for this specific maximization problem [2pts]
    
    \item Solve for 4 possibilities formed by each constraint being active or inactive. Do not forget to check the inactive constraints for each point. Candidate points must satisfy the inactive constraints.   [5pts]
    
    \item List the candidate point(s) (there may be 0, 1, 2, or any number of candidate points)  [4pts]
    
    \item Find the \textbf{one} candidate point for which f(x,y) is largest. Check if L(x,y) is concave or convex at this point by using the \href{https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/quadratic-approximations/a/the-hessian}{Hessian} in the \href{https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/optimizing-multivariable-functions/a/second-partial-derivative-test}{second partial derivative test}.  [2pts]
\end{enumerate}
\textbf{HINT 1:} Click \href{https://www.youtube.com/watch?v=TqN-8fxYUYY}{here} for an example maximization problem. \\
\textbf{HINT 2:} Click \href{https://en.wikipedia.org/wiki/Karush-Kuhn-Tucker_conditions#Nonlinear_optimization_problem}{here} to determine how to set up the problem for minimization in part (a).\\


\newpage
\begin{enumerate}[label=(\alph*)]
    \setcounter{enumi}{5}
    \item \textbf{BONUS FOR ALL:} Make a contour plot of objective function $f(x,y)$ and constraints $g_1$ and $g_2$ using the template \href{https://colab.research.google.com/drive/1DZxRYuurOwEq5S1_-QeFke2lpiNxAeg4?usp=sharing}{Google Colab} code. Mark the maximum candidate point and include a screenshot of your plot. Also include the text output from the last cell in the Google Colab for grading purposes. Lastly, briefly explain why your plot makes sense in one sentence. [4pts]
        \par\textbf{Note 1:} Points on a line in the contour plot have equal values of the objective function. Keeping this in mind, you should be able to figure out the approximate location of the maximum.
        \par\textbf{Note 2:} To use the Google Colab notebook, click "Copy to Drive" upon initial opening
\end{enumerate}


\newpage
\section{Maximum Likelihood [10pts + 15pts Bonus for Undergrads]}
\subsection{Discrete Example [10pts]}
Marion and Shreeya are arguing over which course they should take in Fall 2022. Marion’s argument is that they should take CS-7650 NLP because Professor Roozbahani will teach it. Shreeya’s argument is that they should take CS-7641 ML because it would be difficult to take NLP without having introductory knowledge of Machine Learning.\\

\noindent To resolve this conflict, their other friend Nicole makes a proposition that they should leave it to chance to decide which course they should take. Marion then proposes that Shreeya will toss a 6-sided die 6 times, and Shreeya must get anything except 3 during the first 5 times and must get 3 during the 6th time. Any other combination will make Marion the winner. But Shreeya is also allowed to tamper with the die in any manner she likes to increase her odds.\\

\noindent Now, Shreeya needs you to help her have her way. If the probability of getting a 3 is $\theta$ and the probability of landing on 1 is double of that of landing on 2, 4, 5, and 6, what value of $\theta$ is most likely to ensure that they will have to take CS-7641 ML? Use your expertise of Maximum Likelihood Estimation and probability distribution function to convince Shreeya.\\\\\textbf{NOTE: } \textbf{You must specify the log-likelihood function and use MLE to solve this problem for full credit.} You may assume that the log-likelihood function is concave for this question \\\\


\newpage
\subsection{Weibull distribution [15pts Bonus for Undergrads]}
The Weibull distribution is defined as 
$$P(X=x;\lambda,k)=\frac{k}{\lambda}(\frac{x}{\lambda})^{k-1}e^{-(x/\lambda)^k}\text{, }x \geq 0$$
\begin{enumerate}[label=(\alph*)]
    \item Assume we have one observed data $x_1$, and $X_1 \sim Weibull(\lambda)$, what is the likelihood given $ \lambda$ and k? [2 pts]

    \item Now, assume we are given $n$ such values $(x_1,...,x_n)$, $(X_1, ...,X_n)\sim Weibull(\lambda)$. Here $X_1, ...,X_n$ are i.i.d. random variables. What is the likelihood of this data given $\lambda$ and k? You may leave your answer in product form. [3 pts]

    \item What is the maximum likelihood estimator of $\lambda$? [10 pts]
\end{enumerate}


\newpage
\section{Information Theory [6pts + 19pts + 10pts]}
\subsection{Marginal Distribution [6pts]}
Suppose the joint probability distribution of two binary random variables $X$ and $Y$ are given as follows. X are the rows, and Y are the columns.
$$\renewcommand*{\arraystretch}{1.3}
\begin{tabular}{|c|c|c|}
    \hline 
    \diagbox{X}{Y} & {0} & {1} \\ 
    \hline 0 & {$\frac{1}{16}$} & {$\frac{1}{4}$} \\ 
    \hline 1 & {$\frac{3}{16}$} & {$\frac{1}{2}$} \\ 
    \hline
\end{tabular}$$
\begin{enumerate}[label=(\alph*)]
    \item Show the marginal distribution of $X$ and $Y$, respectively. [3pts]

    \item Find mutual information $I(X,Y)$ for the joint probability distribution in the previous question to at least 3 decimal places (please use base 2 to compute logarithm)   [3pts]
\end{enumerate}


\newpage
\subsection{Mutual Information and Entropy [19pts]}
A recent study has shown symptomatic infections are responsible for higher transmission rates. Using the \href{https://docs.google.com/spreadsheets/d/186WWeuLm4IO2fSLIU-qN9-znGNZtsVQxf36L4PJQin0/edit?usp=sharing}{data} collected from positively tested patients, we wish to determine which feature(s) have the greatest impact on whether or not some will present with symptoms. To do this, we will compute the entropies, conditional entropies, and mutual information of select features. Please use base 2 when computing logarithms.

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{ID}}} & \multicolumn{1}{c|}{\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Age Group \\ ($x_1$)\end{tabular}}}} & \multicolumn{1}{c|}{\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Vaccine Doses \\ ($x_2$)\end{tabular}}}} & \multicolumn{1}{c|}{\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Wears Mask? \\ ($x_3$)\end{tabular}}}} & \multicolumn{1}{c|}{\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Underlying \\ Conditions ($x_4$)\end{tabular}}}} & \multicolumn{1}{c|}{\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Symptomatic \\ ($Y$)\end{tabular}}}} \\
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} \\ \hline \hline
1 & Y & H & F & T & T \\ \hline
2 & Y & H & F & F & F \\ \hline
3 & A & H & F & T & T \\ \hline
4 & S & M & F & T & T \\ \hline
5 & S & L & T & T & T \\ \hline
6 & S & L & T & F & F \\ \hline
7 & A & L & T & F & T \\ \hline
8 & Y & L & F & T & F \\ \hline
9 & Y & L & T & T & F \\ \hline
10 & S & M & T & T & T \\ \hline
\end{tabular}
\caption{Age Groups: \{(Y)outh, (A)dult, (S)enior\}, Vaccine Doses: \{(H) booster, (M) 2 doses, (L) 1 dose\}}
\label{table:1}
\end{table}

\begin{enumerate}[label=(\alph*)]
    \item Find entropy $H(Y)$ to at least 3 decimal places. [3pts]

    \item Find conditional entropy $H(Y|x_2)$, $H(Y|x_4)$, respectively, to at least 3 decimal places. [8pts]

    \item Find mutual information $I(x_2, Y)$ and $I(x_4, Y)$ and determine which one ($x_2$ or $x_4$) is more informative. [4pts]
    \item Find joint entropy $H(Y, x_3)$ to at least 3 decimal places. [4pts]
\end{enumerate}


\newpage
\subsection{Entropy Proofs [10pts]}
\begin{enumerate}[label=(\alph*)]
    \item Write the discrete case mathematical definition for $H(X|Y)$ and $H(X)$. [3pts]
    
    \item \textbf{Using the mathematical definition of $H(X)$ and $H(X|Y)$ from part (a)}, prove that $I(X;Y) = 0$ if $X$ and $Y$ are independent. (Note: you must provide a mathematical proof and cannot use the visualization shown in class \href{https://mahdi-roozbahani.github.io/CS46417641-summer2022/other/CEandMI_Illustration.jpg}{found here})  \\
    \newline
    Start from $I(X;Y) = H(X)-H(X|Y)$ [7pts]
\end{enumerate}


\newpage
\section{Bonus for All [15 pts]}
\begin{enumerate}[label=(\alph*)]
    \item X, Y are two independent $N(0, 1)$ random variables, and we have random variables $P, Q$ defined as 
        \begin{align*}
            P &= 3X + XY^2 \\
            Q &= X
        \end{align*}
        then calculate the variance $Var(P + Q)$ [5pts]
        
    \item Suppose that $X$ and $Y$ have joint pdf given by
        $$f_{X,Y}(x,y)=\left\{
        \begin{aligned}
            &2e^{-2y}, & 0\leq x\leq1,y\geq0 \\
            &0, & otherwise\\
        \end{aligned}\right.$$
    What are the marginal probability density functions for $X$ and  $Y$? [5 pts]

    \item A person decides to toss a biased coin with $P(heads)=0.2$ repeatedly until he gets a head. He will make at most 5 tosses. Let the random variable Y denote the number of heads. Find the variance of Y. [5 pts]
\end{enumerate}
\end{document}
